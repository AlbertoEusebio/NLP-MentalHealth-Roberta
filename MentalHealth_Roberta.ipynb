{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom datasets import load_dataset\nfrom torch.nn import CrossEntropyLoss\nfrom torch.optim import AdamW\nfrom tqdm import tqdm\n\n# Device setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load dataset\ndataset = load_dataset(\"Kanakmi/mental-disorders\")\nnum_labels = len(set(dataset[\"train\"][\"label\"]))\n\n# Tokenizer and model\nmodel_name = \"roberta-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels).to(device)\n\n# Preprocess\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=256)\n\ndataset = dataset.map(tokenize, batched=True)\ndataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n\n# Dataloaders\ntrain_loader = DataLoader(dataset[\"train\"], batch_size=16, shuffle=True)\ntest_loader = DataLoader(dataset[\"test\"], batch_size=16)\n\n# Optimizer and loss\noptimizer = AdamW(model.parameters(), lr=2e-5)\nloss_fn = CrossEntropyLoss()\n\n# Training loop\nepochs = 3\nmodel.train()\nfor epoch in range(epochs):\n    total_loss = 0\n    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n    for batch in loop:\n        optimizer.zero_grad()\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"label\"].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        loss = loss_fn(outputs.logits, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        loop.set_postfix(loss=loss.item())\n\nprint(\"Training complete.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T14:26:53.457705Z","iopub.execute_input":"2025-04-22T14:26:53.458487Z","iopub.status.idle":"2025-04-22T14:32:43.595666Z","shell.execute_reply.started":"2025-04-22T14:26:53.458461Z","shell.execute_reply":"2025-04-22T14:32:43.594635Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport pandas as pd\nimport numpy as np\n\nmodel.eval()\nall_preds = []\nall_labels = []\nall_texts = []\n\nwith torch.no_grad():\n    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"label\"].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        preds = torch.argmax(outputs.logits, dim=1)\n\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n        # Store raw text if you want CSV output\n        batch_texts = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n        all_texts.extend(batch_texts)\n\n# Classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(all_labels, all_preds))\n\n# Confusion matrix\nprint(\"\\nConfusion Matrix:\")\nprint(confusion_matrix(all_labels, all_preds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T14:32:49.007329Z","iopub.execute_input":"2025-04-22T14:32:49.007604Z","iopub.status.idle":"2025-04-22T14:35:34.509513Z","shell.execute_reply.started":"2025-04-22T14:32:49.007584Z","shell.execute_reply":"2025-04-22T14:35:34.508670Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\n\ncm = confusion_matrix(all_labels, all_preds)\n\nsns.heatmap(cm, annot=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T14:37:06.303627Z","iopub.execute_input":"2025-04-22T14:37:06.304277Z","iopub.status.idle":"2025-04-22T14:37:06.581393Z","shell.execute_reply.started":"2025-04-22T14:37:06.304252Z","shell.execute_reply":"2025-04-22T14:37:06.580669Z"}},"outputs":[],"execution_count":null}]}